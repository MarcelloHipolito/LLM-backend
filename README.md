# ðŸ§  Backend LLM com OpenRouter

Este backend em Node.js fornece uma rota de API para realizar consultas a um modelo LLM (Large Language Model) via [OpenRouter.ai](https://openrouter.ai/), retornando respostas com base em um contexto fornecido.

## ðŸš€ Como rodar

### 1. Instale as dependÃªncias

```bash
npm install
```

### 2. Configure sua chave de API do OpenRouter

Crie um arquivo `.env` na raiz do projeto com o seguinte conteÃºdo:

```
OPENROUTER_API_KEY=sk-or-xxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

VocÃª pode gerar uma chave gratuita em: [https://openrouter.ai/keys](https://openrouter.ai/keys)

### 3. Inicie o servidor

```bash
node index.js
```

O backend serÃ¡ executado em:  
ðŸ“¡ `http://localhost:3000`

## ðŸ§ª Testando a API

VocÃª pode fazer um POST em:

```
POST /api/perguntar
```

Com o seguinte corpo JSON:

```json
{
  "contexto": "jurÃ­dico",
  "pergunta": "O que Ã© habeas corpus?"
}
```

A resposta serÃ¡ semelhante a:

```json
{
  "resposta": "Habeas corpus Ã© uma aÃ§Ã£o constitucional..."
}
```

## ðŸ“š Tecnologias utilizadas

- Node.js
- Express
- Axios
- dotenv
- OpenRouter API
